# lgm_influenza

Analysis of influenza genomes generated from respiratory swab samples collected in Perú.

This notebook contains code and documentation for the anlaysis of seasonal influenza virus genomes sampled from symptomatic patients in Lima, Perú. Samples were collected by the PISAAC clinical network.

This repository is based on and uses some code from the simplified avian-flu build called "quickstart", created by Louise Moncla.

It was ported from the (lgm_rsv)[https://github.com/dbacsik/lgm_rsv] repository, created by David Bacsik and Diego Cuicapuza.

## Best Practices
### Commits and pull requests are required
**Please do not edit the codebase directly.**
All changes should be documented in commits. Small commits are strongly preferred over large ones. Commits should have brief descriptive commit messages (1 sentence or less).
**Pull requests are required.** These should have longer descriptions, and should include both the goal of the PR and any critical technical details. Peer review is not required and you may merge your own pull requests.

### First contribution
When you make your first contribution, please add your name to the Copyright (line 3) of the [LICENSE](./LICENSE) document.

### Style guide
Please try to conform to the following style guide, with some important additions/exceptions: [https://www.classes.cs.uchicago.edu/archive/2017/fall/12100-1/style-guide/index.html](https://www.classes.cs.uchicago.edu/archive/2017/fall/12100-1/style-guide/index.html)

- Variable names should be brief and descriptive. Whole words are preferred to abbreviations.
- By default, variable names should not include their datatype. Specifically, df need not be used.
- Data is organized in [long-form Tidy format ](https://kiwidamien.github.io/what-is-tidy-data.html) for storage and manipulation whenever possible.
- One or few CSV files are input and output from each notebook or script. The data in these is selected carefully.

## Project organization
### Builds
This project answers several different questions. For each question, a different analysis workflow is performed. Each analysis workflow is a called a build.

Files generated for each build are named with the prefix `build-` (e.g. `build-regional.yml`). When there are many build-specific files, a build-specific folder is added (e.g. `output/build-region/`).

An example of all of the files for a build is this:

```
Input:  input/data/build-lineages/RSVA_lineages.fasta
Config: config/build-lineages.yml
Snakemake:  workflow/smks/build-lineages.smk
Interim files:
    output/build-lineages/data/
    output/build-lineages/alignment/
    output/build-lineages/tree/
Output: output/auspice/build-lineages.json
```

## Data in and data out
### Input
All data that is taken in from an external source (outside of this pipeline) is placed in the in the [input](./input) directory.

### Config
Config files are stored in the [config](./config) folder.

### Interim files
After data has been processed by the pipeline, it is put in an [output](./output) subdirectory.

### Results
Final result files generated by the workflow are output to the [output/auspice](./output/auspice) directory.

## Organizing workflows
### Snakemake
This project uses Snakemake files to organize workflows. Each task is given a rule in a [.smk file stored in workflow/smks](./workflow/smks). The [main Snakefile](.Snakefile) collates these in a simple way.

### Scripts and notebooks
#### Scripts
Custom scripts are stored in the [scripts/](./workflow/scripts/) directory. Scripts are named based on their function.

#### Manual processing
Processing things by hand is avoided when possible. If something must be done by hand, it is stored in the [workflow/manual](./workflow/manual/) directory.
